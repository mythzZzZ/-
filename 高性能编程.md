# 1.理解高性能编程

## 1.如何提升程序的运算时间

- 程序执行时，需要利用RAM，CPU等等，有效减少这些硬件之间的通讯速度可以达到程序运算时间提升的目的
- 此时提出了并行，矢量化编程（减少数据传输到CPU的次数，把所有数据一次就传给了CPU）【为什么GPU比CPU快，可以一次计算Tensor里面的所有值，而CPU只能计算一次】



## 2.python慢的原因

1.python虚拟机抽象层的影响，python的矢量化操作不能直接使用，需要借助numpy库

2.python内存分配是自动的，会存在内存碎片，影响CPU缓存的传输

3.python具有动态类型，且不是编译型语言

- 编译型语言的好处，编译器可以改变它的内存布局，且让CPU运行某种指令优化他们
- 使用CPython来解决

4.python的全局解释器锁（GIL），让python不能使用CPU的多个核心，一次只能使用一个核心

- 使用多进程，cpython，外部函数来解决







# 2.通过性能分析找到瓶颈



## 1.使用自定义装饰器，看函数执行完使用的时间

- @timefn

```python
from functools import wraps
import time
def timefn(fn):
    @wraps(fn)
    def measure_time(*args,**kwargs):
        t1 = time.time()
        result = fn(*args,**kwargs)
        t2 = time.time()
        print("@timefn:"+fn.__name__ + "took" + str(t2-t1) + "second")
        return result
    return measure_time

@timefn
def c(a):
    for i in range(a):
        c


c(1000000)
```

- timeit



## 2.wraps装饰器的作用

函数被装饰器装饰后，它的\__doc\__，__name\__属性会变，要不想函数的这些属性变，在定义装饰器时，要wraps函数一下



## 3.各种分析效率的工具



## 4.使用dis模块检查字节码

一些内置函数速度比较快的原因

- 底层用C编写，知道如何生成最后的结果而无需创建中间的python对象





## 5，代码单元测试







# 3.列表和元组



1.元组的不可变类型在内存分配中有很大的优势

- 两个元组可以组合成一个新的元组 组合之后不用重新分配额外的空间
- 元组的静态特性
  - python是一门垃圾收集语言，意味着当一个变量不用时，python会将该变量的内存释放回操作系统，给其他程序使用。长度为1-20的元组 即使他们不使用，她的空间也不会立刻被还给系统，而是留着未来使用。意味着要申请同样大小的新元组时，不需要向操作系统申请内存来存放数据。避免了跟==操作系统(内核)打交道== 节省了很多时间。

2.列表的超额分配，列表的地址是不连续的，元组的地址是连续的，连续的速度更快





# 4.字典和集合



缺点：使用字典和集合占用更多的内存，虽然插入和查询的时间复杂的是o1，但实际速度极大取决于其使用的散列函数（散列函数将任意的键（字符串）转变成了一个列表的索引），如果散列函数的速度慢，他就慢



集合的速度比列表快得多

 

## 1.字典和集合的插入和获取

插入位置的选取：索引键的散列值



散列碰撞



嗅探

散列函数的熵：散列函数分布均匀程度

- 熵最大的散列函数是完美散列函数



## 2.字典和命名空间

python访问一个变量，函数，模块的查询顺序

locals数组

globals字典

__builtin\__对象

- builtin是模块的对象，搜索builtin时，是搜索它里面的属性，其实也是搜索它里面的locals数组

如果把要调用的函数一开始就放到locals里面，则程序的运行速度会变快









# 5.迭代器和生成器

 for循环与生成器循环的区别

- ```python
  # for循环
  for i in range(10)
  range返回的是一个长度为10的列表，每次便利一个数，把这个数存入列表中 然后返回给for循环
  
  但是存在一个问题
  依次遍历数字存入列表中每一个append操作消耗相当大的内存
  
  使用for进行遍历时，需要生成一个迭代器
  
  #生成器循环
  for i in xrange(10)
  
  xrange根据传进去的参数生成很多数，这些数并不是存入列表中的，生成的数给for调用
  
  使用生成器生成的数，自动拥有迭代器，不需手动生成
  生成器少了每一个数的append的操作，大大降低了需要使用的内存
  
  
  ```

  

  

  

  

  ## 1.无穷数列的迭代器

  执行fibonacci第一次执行前面所有代码，后面只执行i,j = j,i+j

  ```python
  def fibonacci():
      i,j = 0,1
      while True:
          yield j
          i,j = j,i+j
  
  
  def fibo_tra():
      count = 0
      for f in fibonacci():
          if f > 5000:
              break
          if f % 2 :
              count += 1
  
      return count
  
  
  
  fibo_tra()
  ```

  

## 2.生成器的延迟估计



生成器节约内存的原因

- 只处理当前感兴趣的值，无法访问其他元素（单通，在线 ）







# 6.矩阵和矢量计算

## 2.python列表还不够吗

列表重用已经分配好的空间，避免重新分配占用更多不需要的资源



## 3.内存碎片

python进行矢量化计算的核心问题

- python列表存储的是指向实际数据的指针（python不用指定数据类型的原因，但是对于矢量和矩阵操作，这回导致大幅度的性能下降【因为需要对地址进行寻址查找数据，如果数据不在一个连续的块里面，是分散的一片片分别传输这意味着要引入更多的内存开销】）
- python字节码没有针对矢量操作进行优化，for循环无法预测何时使用矢量操作能带来好处



冯诺依曼瓶颈：

- 数据传输给CPU问题【内存与cpu的问题】
- 如果传输的速度可以无限快，则我们就不需要任何缓存，CPU拿到数据就可以立即执行



异步操作

- 理论上CPU每次只能执行一个程序，当该程序访问IO时（内存磁盘网络），内核会将CPU里的该条程序暂时挂起，此时可以使用异步操作确保程序在等待IO时继续使用CPU，会让我们的程序继续运行不被切出去



python是使用C语言写的 使用python的==内建机制进行运算==，就可以获得原生C代码的速度

numpy可以进行矢量化计算的原因

- numpy中存放的数据在内存中是连续的
- 使用了高度优化且特殊构建的对象取代了通用的列表结构来处理数组（numpy模块底层使用C写的，可以进行矢量化计算所以速度很快）
- numpy使用了较少的CPU指令，因为一条指定可以对多个数据进行操作
- 事实上numpy速度那么快的根本原因是内存的本地性以及减少的内存碎片



## 4.内存分配和就地操作

内存分配

- 缓存中没有我们需要的数据时，要从RAM中找到该数据
- 内存分配需要向操作系统请求一块可用的数据并保留它



内存就地操作减少了内存的重新分配开销，可以节省很多时间

- 就地操作的缺点
  - 覆盖了原来的数据
  - 代码可读性变差

```python
import numpy as np
a1 = np.random.random((10,10))
a2 = np.random.random((10,10))
print(id(a1))
a1 += a2 # 内存就地操作
print(id(a1))

a1 = a1 + a2  #内存地址改变
print(id(a1))

```



## 总结

优化的两种方法

- 减少CPU获得数据的时间和减少CPU需要干的工作









# 7.编译成C

让代码执行更少指令的最简单的方法就是把你的代码编译成机器码



各种编译器





# 8.并发

IO等待

- 程序在等待IO操作（程序读取磁盘，内存，网络）所需要的时间



并发

- 我们在等待一个IO操作完成的时候执行其他操作，把浪费的时间利用起来
- 同时运行不同的任务隐藏掉等待的时间，这些都发生在一个单独的线程上，还是每次只使用一个CPU



## 1.异步编程介绍

内核的上下文切换

- 程序进入IO等待时，内核就能进行IO请求相关的低级操作，直到IO操作完成时才继续



上下文切换的缺点

- 相当重量级的操作
- 保持了程序的状态，丢失了程序在CPU层面上任何类型的缓存
- 程序访问完IO可以再次运行时，必须花时间在主板上重新初始化程序并准备好继续运行



并发的典型情况

- 事件循环【列表顶端的函数得到运行，接着轮到下一个】



事件循环的两种方式

- 回调（把一个函数指针当作参数传入一个函数）
- future（生成器实现协程）



上下文切换和事件循环的结合（回调与异步的目的）

- 请求一个IO操作时，在等待原来的IO完成期间，可以运行另外的函数





回调函数异步调用

[回调函数](https://zhuanlan.zhihu.com/p/491684301)









# 9.multiprocessing模块

避免进程之间的通信 可以加速



python

- 使用进程来做CPU密集型任务（用进程并行）
  - python中的线程是OS原生的，被全局解释锁==GIL锁==束缚，所以同一时刻只有一个线程可以和Python对象交互



C++，java

- 使用线程来做CPU密集型任务（用线程并行）





python的**并行**

- 使用进程
- 不同进程并行运行一定数量的python解释器，每一个进程都有私有的内存空间，有自己的GIL，不同进程的GIL不会相互影响



## 9.1multiprocessing模块综述

 



## 9.3使用python对象

使用pool函数创建进程池

pool.map的使用



进程的创建

- 在Linux系统上创建进程会占用一定的时间，Linux具有派生(fork)进程，python通过克隆父进程fork来创建新进程，windows没有fork进程



GIL

- GIL把线程锁死，CPU每次只能计算一个线程的任务

- python多线程在IO密集型任务有优势，但是队友CPU密集型则是糟糕的选择，多个线程会出现GIL竞争，导致代码运行更慢







chunksize

- 可以控制每个进程的工作量
- chunksize=10意味着每一个进程处理一列10个整数，工作块数=总数 / chunksize
- chunksize数量与CPU数量保持一致比较好（默认）





工作队列

- 处理进程之间的通信

- 缺乏 持久性
- 可以设置进程间共享的标记，用来同步进程间的工作状态，刷新共享标记会消耗资源，多久刷新一次共享标记需要自己探索



Redis

- 让python进程共享状态，而且还与其他工具和其他机器来共享，甚至通过一个web浏览器接口来暴露状态（可能对远程监控有用）
- 让数据存储变得与语言无关，任何与redis有接口的语言或工具都能以一种可兼容的方式共享数据



进程间的通讯

- 共享资源块，加锁锁住资源防止冲突（防止同时读取或写入）









# 10.集群







# 11.使用更少的RAM

列表存放数据

- 内存不连续，低效



array存放数据

- 高效的存储基础类型数据
- 创建连续的RAM来保存底层数据





numpy存放数据



python2.x使用str节约RAM

python3.x使用Unicode节约RAM



trie和DAWG（有向无环单词图）让字符串占用更少的RAM

- 共享了字符串相同的部分
- 共享前缀，后缀



DAWG（有向无环单词图）

- 创建后不能被修改，读取一个迭代器来创建自己



各种树来节约RAM的使用

- Marisa trie
- Datrie 
- HAT trie
- 



各种计数器



# 12.现场教训
